{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recycle  :  ../Plastic/recycle\\recycle1.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle127.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle154.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle181.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle208.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle235.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle2620.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle2891.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle3160.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle3430.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle533.jpg\n",
      "recycle  :  ../Plastic/recycle\\recycle804.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle1.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle1278.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle1548.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle1818.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle2088.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle2358.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle2628.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle2899.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle3197.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle543.jpg\n",
      "Non_recycle  :  ../Plastic/Non_recycle\\Non-recycle813.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, sys, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "img_dir = \"../Plastic\"\n",
    "categories = [\"recycle\", \"Non_recycle\"]\n",
    "np_classes = len(categories)\n",
    "\n",
    "image_w = 28\n",
    "image_h = 28\n",
    "\n",
    "\n",
    "pixel = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    img_dir_detail = img_dir + \"/\" + cat\n",
    "    files = glob.glob(img_dir_detail+\"/*.jpg\")\n",
    "\n",
    "\n",
    "    for i, f in enumerate(files):\n",
    "        try:\n",
    "            img = Image.open(f)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h))\n",
    "            data = np.asarray(img)\n",
    "            #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
    "            X.append(data)\n",
    "            y.append(idx)\n",
    "            if i % 300 == 0:\n",
    "                print(cat, \" : \", f)\n",
    "        except:\n",
    "            print(cat, str(i)+\" 번째에서 에러 \")\n",
    "X = np.array(X)\n",
    "Y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "xy = (X_train, X_test, Y_train, Y_test)\n",
    "np.save(\"../Plastic/binary_image_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6048, 28, 28, 3)\n",
      "6048\n",
      "[3166 2882]\n",
      "[350 323]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('../Plastic/binary_image_data.npy', allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = 28\n",
    "image_h = 28\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model_dir = './model'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = model_dir + \"./recycle_classify.model\"\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 82,465\n",
      "Trainable params: 82,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5140 samples, validate on 908 samples\n",
      "Epoch 1/100\n",
      "5140/5140 [==============================] - 4s 863us/step - loss: 0.6726 - accuracy: 0.5574 - val_loss: 0.5104 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51045, saving model to ./model./recycle_classify.model\n",
      "Epoch 2/100\n",
      "5140/5140 [==============================] - 4s 739us/step - loss: 0.4538 - accuracy: 0.7790 - val_loss: 0.3794 - val_accuracy: 0.8304\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51045 to 0.37939, saving model to ./model./recycle_classify.model\n",
      "Epoch 3/100\n",
      "5140/5140 [==============================] - 4s 781us/step - loss: 0.3784 - accuracy: 0.8315 - val_loss: 0.3520 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37939 to 0.35197, saving model to ./model./recycle_classify.model\n",
      "Epoch 4/100\n",
      "5140/5140 [==============================] - 4s 749us/step - loss: 0.3172 - accuracy: 0.8628 - val_loss: 0.3007 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35197 to 0.30066, saving model to ./model./recycle_classify.model\n",
      "Epoch 5/100\n",
      "5140/5140 [==============================] - 4s 740us/step - loss: 0.2765 - accuracy: 0.8821 - val_loss: 0.4774 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30066\n",
      "Epoch 6/100\n",
      "5140/5140 [==============================] - 4s 732us/step - loss: 0.2549 - accuracy: 0.8932 - val_loss: 0.2348 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30066 to 0.23482, saving model to ./model./recycle_classify.model\n",
      "Epoch 7/100\n",
      "5140/5140 [==============================] - 4s 741us/step - loss: 0.2070 - accuracy: 0.9140 - val_loss: 0.1821 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23482 to 0.18213, saving model to ./model./recycle_classify.model\n",
      "Epoch 8/100\n",
      "5140/5140 [==============================] - 4s 738us/step - loss: 0.1750 - accuracy: 0.9327 - val_loss: 0.1705 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18213 to 0.17053, saving model to ./model./recycle_classify.model\n",
      "Epoch 9/100\n",
      "5140/5140 [==============================] - 4s 739us/step - loss: 0.1732 - accuracy: 0.9333 - val_loss: 0.1749 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17053\n",
      "Epoch 10/100\n",
      "5140/5140 [==============================] - 4s 714us/step - loss: 0.1413 - accuracy: 0.9469 - val_loss: 0.1287 - val_accuracy: 0.9559\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.17053 to 0.12865, saving model to ./model./recycle_classify.model\n",
      "Epoch 11/100\n",
      "5140/5140 [==============================] - 4s 734us/step - loss: 0.1293 - accuracy: 0.9533 - val_loss: 0.1213 - val_accuracy: 0.9604\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12865 to 0.12127, saving model to ./model./recycle_classify.model\n",
      "Epoch 12/100\n",
      "5140/5140 [==============================] - 4s 742us/step - loss: 0.1156 - accuracy: 0.9613 - val_loss: 0.2623 - val_accuracy: 0.8965\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12127\n",
      "Epoch 13/100\n",
      "5140/5140 [==============================] - 4s 735us/step - loss: 0.1201 - accuracy: 0.9582 - val_loss: 0.1003 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12127 to 0.10031, saving model to ./model./recycle_classify.model\n",
      "Epoch 14/100\n",
      "5140/5140 [==============================] - 4s 760us/step - loss: 0.0962 - accuracy: 0.9677 - val_loss: 0.0870 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10031 to 0.08704, saving model to ./model./recycle_classify.model\n",
      "Epoch 15/100\n",
      "5140/5140 [==============================] - 4s 755us/step - loss: 0.0990 - accuracy: 0.9681 - val_loss: 0.1040 - val_accuracy: 0.9604\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08704\n",
      "Epoch 16/100\n",
      "5140/5140 [==============================] - 4s 755us/step - loss: 0.0764 - accuracy: 0.9765 - val_loss: 0.1048 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08704\n",
      "Epoch 17/100\n",
      "5140/5140 [==============================] - 4s 747us/step - loss: 0.0887 - accuracy: 0.9695 - val_loss: 0.0992 - val_accuracy: 0.9637\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08704\n",
      "Epoch 18/100\n",
      "5140/5140 [==============================] - 4s 760us/step - loss: 0.0684 - accuracy: 0.9805 - val_loss: 0.1160 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08704\n",
      "Epoch 19/100\n",
      "5140/5140 [==============================] - 4s 783us/step - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.1423 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08704\n",
      "Epoch 20/100\n",
      "5140/5140 [==============================] - 4s 833us/step - loss: 0.0841 - accuracy: 0.9708 - val_loss: 0.1587 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08704\n",
      "Epoch 21/100\n",
      "5140/5140 [==============================] - 4s 819us/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0794 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08704 to 0.07940, saving model to ./model./recycle_classify.model\n",
      "Epoch 22/100\n",
      "5140/5140 [==============================] - 4s 820us/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 0.0740 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07940 to 0.07400, saving model to ./model./recycle_classify.model\n",
      "Epoch 23/100\n",
      "5140/5140 [==============================] - 4s 768us/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0625 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07400 to 0.06251, saving model to ./model./recycle_classify.model\n",
      "Epoch 24/100\n",
      "5140/5140 [==============================] - 4s 840us/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.0726 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06251\n",
      "Epoch 25/100\n",
      "5140/5140 [==============================] - 6s 1ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.0902 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06251\n",
      "Epoch 26/100\n",
      "5140/5140 [==============================] - 8s 2ms/step - loss: 0.0594 - accuracy: 0.9819 - val_loss: 0.0672 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06251\n",
      "Epoch 27/100\n",
      "5140/5140 [==============================] - 6s 1ms/step - loss: 0.0740 - accuracy: 0.9753 - val_loss: 0.0865 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06251\n",
      "Epoch 28/100\n",
      "5140/5140 [==============================] - 6s 1ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 0.0602 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06251 to 0.06020, saving model to ./model./recycle_classify.model\n",
      "Epoch 29/100\n",
      "5140/5140 [==============================] - 4s 854us/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 0.1127 - val_accuracy: 0.9604\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06020\n",
      "Epoch 30/100\n",
      "5140/5140 [==============================] - 4s 801us/step - loss: 0.0548 - accuracy: 0.9819 - val_loss: 0.0739 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06020\n",
      "Epoch 31/100\n",
      "5140/5140 [==============================] - 4s 787us/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.0776 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06020\n",
      "Epoch 32/100\n",
      "5140/5140 [==============================] - 4s 847us/step - loss: 0.0455 - accuracy: 0.9846 - val_loss: 0.0994 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06020\n",
      "Epoch 33/100\n",
      "5140/5140 [==============================] - 4s 850us/step - loss: 0.0493 - accuracy: 0.9833 - val_loss: 0.0694 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06020\n",
      "Epoch 34/100\n",
      "5140/5140 [==============================] - 5s 904us/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0849 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06020\n",
      "Epoch 35/100\n",
      "5140/5140 [==============================] - 5s 1ms/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 0.0815 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.15, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 0s 320us/step\n",
      "정확도 : 0.98 \n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 ../Plastic/testNon-recycle16.jpg  이미지는 재활용불가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testNon-recycle3.jpg  이미지는 재활용불가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testNon-recycle34.jpg  이미지는 재활용불가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testNon-recycle95.jpg  이미지는 재활용불가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testrecycle11.jpg  이미지는 재활용가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testrecycle24.jpg  이미지는 재활용가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testrecycle466.jpg  이미지는 재활용불가능 으로 추정됩니다.\n",
      "해당 ../Plastic/testrecycle64.jpg  이미지는 재활용가능 으로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 5\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "caltech_dir = '../Plastic/test'\n",
    "\n",
    "image_w = 28\n",
    "image_h = 28\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.astype(float) / 255\n",
    "model = load_model('./model/recycle_classify.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        print(\"해당 \" + filenames[cnt].split(\"\\\\\")[0] + filenames[cnt].split(\"\\\\\")[1] + \"  이미지는 재활용불가능 으로 추정됩니다.\")\n",
    "    else :\n",
    "        print(\"해당 \" + filenames[cnt].split(\"\\\\\")[0] + filenames[cnt].split(\"\\\\\")[1] + \"  이미지는 재활용가능 으로 추정됩니다.\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1.15",
   "language": "python",
   "name": "tensorflow1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
